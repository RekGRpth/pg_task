# Планировщик асинхронных заданий. Прошлое, настоящее и будущее.

## Прошлое или как появился планировщик.

Вкратце на вопрос, зачем я написал свой планировщик асинхронных заданий можно ответить так: потому, что я устал ждать, когда это сделает кто-то другой.
С 2007 года я занимался биллингом.
Изначально он был написан на перле с базой пострегс, позднее его частично перевели на джангу.
Большинство задач в биллинге можно было решать прямо в базе.
Например, что-то посчитать, протарифицировать, включить, выключить.
Но решались они внешними скриптами на перле и питоне, которые по сути выполняли всего лишь SQL-запросы в базе.
Поэтому когда на очередном собеседовании летом 2018 меня спросили, что мне не хватает в постгресе, я не задумываясь на первом месте назвал асинхронные триггеры.
(На втором месте - внешние ключи на партицированные таблицы.
На третьем - мультимастер.)
Асинхронные триггеры - это как триггеры, но только выполняются асинхронно.
Например, клиент в биллинге совершает платёж на свой лицевой счёт через платёжный шлюз.
Платёжный шлюз запрашивает информацию у биллинга на существование такого лицевого счёта и на возможность пополнения баланса.
В случае успешного ответа платёж совершается.
Далее биллинг считает баланс для лицевого счёта и в зависимости от результата может совершать дальнейшие действия, например, включить телефон/интернет.
Все эти действия по-сути являются просто SQL-запросами в базе и могут быть зашиты в хранимки и триггеры.
Но обычные триггеры синхронны по отношению к запросу.
Поэтому в таком случае платёжному шлюзу пришлось бы ждать, пока биллинг завершит все нужные действия, хотя они вовсе не обязательны для платёжного шлюза.
А вот в случае асинхронных триггеров данные действия могут выполняться асинхронно, не тормозя платёжный шлюз, сколько бы их не было и как бы долго они не выполнялись.
Сначала я поискал, что есть готового для решения этого вопроса и нашёл
1) [PGQ](https://github.com/pgq/pgq) - асинхронные очереди прямо в базе
2) [pg_cron](https://github.com/citusdata/pg_cron) - cron прямо в базе
3) [pg_background](https://github.com/vibhorkum/pg_background) - выполнение запроса в фоне асинхронно

и конечно же коммерческий планировщик [pgpro_scheduler](https://habr.com/ru/company/postgrespro/blog/335798/)
Позже, когда я уже написал свой планировщик, я случайно нашёл один открытый планировщик [generic-scheduler](https://github.com/okbob/generic-scheduler).
Сначала я попытался заюзать асинхронные очереди [PGQ](https://github.com/pgq/pgq).
Для работы они требуют [управляющего-тикера](https://github.com/pgq/pgqd) - внешнюю программу, которая нарезает задачи для выполнения исполнителям - тоже внешним программам, которые постоянно опрашивают базу на предмет новых задач для них.
Подобная архитектура меня не устроила и первое, что я сделал - это перенёс тикера в базу в качестве фонового рабочего процесса.
Так появилась первоначальная версия моего планировщика [pgqbw](https://github.com/RekGRpth/pgqbw).
Но всё равно исполнители оставались внешними программами и более того, какое-то их количество должно быть всегда запущено, даже если задач для них совсем нет.
Такой подход меня не устроил, мне бы хотелось динамически запускать исполнителей при наличии задач и останавливать их при отсутствии задач.
Подобным образом работает [pg_cron](https://github.com/citusdata/pg_cron), но на тот момент у него было много других ограничений, которые меня тоже не устраивали.
Например, он проверял появление новых заданий не чаще чем раз в минуту (мой планировщик может проверять не чаще чем раз в миллисекунду).
Также [pg_cron](https://github.com/citusdata/pg_cron) не мог выполнять одновременно несколько задач (мой планировщик не имеет такого ограничения).
Ещё [pg_cron](https://github.com/citusdata/pg_cron) мог быть запущен только в одной базе для всего кластера (мой планировщик может запускаться в каждой базе да не по разу если надо).
Кроме того, [pg_cron](https://github.com/citusdata/pg_cron) - это был просто cron, т.е. какие-то периодические задачи, там нельзя было что-то выполнить один раз в определённую дату в определённое время.
Также мне не подошёл [pg_background](https://github.com/vibhorkum/pg_background), потому, что это просто асинхронное выполнение запроса в фоне, причём почти бесконтрольно.
Поэтому, т.к. я не смог использовать найденные открытые решения так как мне надо, я решил написать свой планировщик асинхронных заданий и назвал его [pg_task](https://github.com/RekGRpth/pg_task).
Работу над планировщиком я начал осенью 2018, в то время актуальная версия постгреса была 10, но вскоре уже сменилась на 11.
Шло время, версии постгреса менялись, планировщик совершенствовался, я старался не отставать от новых версий постгреса.
Осенью 2021, когда актуальной версией постгреса уже была 14, меня спросили, какие версии поддерживает планировщик.
Тогда я подумал, что по-идее, он должен поддерживать и старые версии.
Каково же было моё разочарование, когда планировщик не скомпилировался даже на предпредыдущей (12) версии!
Я стал более подробно изучать этот вопрос и постепенно примерно за месяц мне удалось снизить минимально поддерживаемую версию аж до 9.4.
В то время я ещё не слышал про гринплам, поэтому минимально поддерживаемая версия планировщиком 9.4 - это приятное случайное совпадение.
Почему именно 9.4? Да потому,что уже в 9.3 в пострегсе ещё не появились динамические фоновые процессы, как раз которые я очень активно использую в планировщике.
Летом 2022 я узнал про гринплам и, когда осенью 2022 я уже порядочно изучил его, то я подумал, почему бы не сделать в планировщике поддержку и гринплама.
Всего за каких-то буквально пару часов планировщик уже работал в 6 и 7 версиях гринплама.
Это удалось сделать так быстро благодаря хорошо продуманной архитектуре планировщика, а также тому, что ранее мне удалось сделать поддержку планировщиком версии 9.4 постгреса, на основе которой как раз работает гринплам 6 версии.

## Настоящее или что умеет планировщик.

Чтобы запустить планировщик асинхронных заданий [pg_task](https://github.com/RekGRpth/pg_task) достаточно прописать его в `shared_preload_libraries`
```conf
shared_preload_libraries = 'pg_task'
```
и перезагрузить кластер пострегс.
При этом, по-умолчанию, планировщик запустит новый фоновый рабочий процесс `pg_work` в базе `postgres` от пользователя `postgres` и создаст в ней таблицу с заданиями `task` в схеме `public`, а затем будет проверять наличие заданий для выполнения в этой таблице каждую секунду.
Чтобы выполнить некий SQL-запрос асинхронно как можно быстрее, достаточно вставить его в текстовое поле `input` таблицы с заданиями:
```sql
INSERT INTO task (input) VALUES ('SELECT now()'); -- выполнить запрос локально как можно быстрее
```
При этом, при очередной проверке заданий для выполнения (которая происходит каждую секунду, по-умолчанию), планировщик увидит это новое задание и запустит новый фоновый рабочей процесс `pg_task` (с той же базой и пользователем, что и у `pg_work`), который и выполнит запрос, записав результат обратно в таблицу с заданиями в текстовое поле `output`.
Если же запрос нужно выполнить в удалённой базе, то параметры подключения к ней можно передать в текстовое поле `remote`:
```sql
INSERT INTO task (input, remote) VALUES ('SELECT now()', 'user=user host=host'); -- выполнить запрос удалённо как можно быстрее
```
При этом, опять же, при очередной проверке планировщик подключится к указанной удалённой базе, выполнит в ней запрос и запишет результат обратно в таблицу.
При выполнении запросов планировщик записывает текущий статус выполнения в перечисляемое поле `state`, значениями которого могут быть
- PLAN - задача запланирована для выполнения (по-умолчанию)
- TAKE - задача взята для выполнения
- WORK - задача выполняется
- DONE - задача выполнена
- STOP - задачу не надо выполнять

Перед выполнением запроса планировщик записывает фактическое время начала выполнения в поле `start`, а также идентификатор обрабатывающего запрос процесса в целочисленное поле `pid`.
После выполнения запроса планировщик записывает фактическое время окончания в поле `stop`.
Если при выполнении запроса произойдёт какая-то ошибка, то сообщение об ошибке планировщик запишет в текстовое поле `error`:
```sql
INSERT INTO task (input) VALUES ('SELECT 1/0');
INSERT INTO task (input, remote) VALUES ('SELECT 1/0', 'user=user host=host');
```
Чтобы выполнить запрос в указанное время, достаточно указать его в поле `plan` (по-умолчанию там будет текущее время):
```sql
INSERT INTO task (plan, input) VALUES (now() + '5 min':INTERVAL, 'SELECT now()'); -- выполнить запрос через 5 минут
INSERT INTO task (plan, input) VALUES ('2029-07-01 12:51:00', 'SELECT now()'); -- выполнить запрос в указанное время в указанную дату
```
При этом планировщик будет выполнять такие запросы только при наступлении указанного времени.
Для автоматического повторения запроса через равные промежутки времени, можно указать требуемый интервал в поле `repeat`:
```sql
INSERT INTO task (repeat, input) VALUES ('5 min', 'SELECT now()'); -- повторять запрос каждые 5 минут
```
При этом планировщик будет каждые 5 минут выполнять запрос (автоматически создавая новую задачу для этого, в которой сохраняются все нужные поля).
По-умолчанию, планировщик выполняет одновременно только одну задачу, но если нужно выполнять несколько, то это можно указать в целочисленном поле `max` (по-умолчанию, там будет 0):
```sql
INSERT INTO task (max, input) SELECT 1, 'SELECT pg_sleep(10)' FROM generate_series(1, 10); -- выполнить 10 запросов, одновременно выполняя по два запроса
```
Здесь число 1 в поле `max` означает запускать одну задачу параллельно уже запущенной, т.е. всего будет выполняться 2 задачи одновременно.
Если, пока выполняются задачи как выше, в поле `max` указать число 2
```sql
INSERT INTO task (max, input) VALUES (2, 'SELECT now()'); -- выполнить запрос параллельно к двум уже запущенным
```
то планировщик запустит новую задачу параллельно к двум уже запущенным, несмотря на то, что еще не выполнились все задачи у которых в поле `max` было число 1.
Также, это можно рассматривать как некое подобие приоритета выполнения в задачах.
Здесь нужно упомянуть ещё то, что планировщик выполняет задачи в порядки их поступления последовательно (при прочих равных условиях), т.е. упорядочивая таблицу по автоинкрементирующемуся целочисленному полю `id`.
Задачи можно группировать, задавая разные текстовые поля `group` (по-умолчанию, там будет строка group):
```sql
INSERT INTO task (group, max, input) SELECT 'one', 1, 'SELECT pg_sleep(10)' FROM generate_series(1, 10); -- выполнить 10 запросов, одновременно выполняя по два запроса в одной группе
INSERT INTO task (group, max, input) SELECT 'two', 1, 'SELECT pg_sleep(10)' FROM generate_series(1, 10); -- выполнить 10 запросов, одновременно выполняя по два запроса в другой группе
```
Т.е. будет выполняться одновременно 4 запроса, 2 для одной группы и 2 для другой.
На самом деле, группировка выполяется по целочисленному полю `hash`, которое вычисляется как хэш от полей `group` и `remote`.
Т.о. планировщик может выполнять запросы последовательно и/или параллельно.
Но есть ещё и третий возможный вариант - антипараллельное выполнение запросов.
Это когда запросы выполняются последовательно один за одним (в группе), но с заданными промежутками-паузами между выполнением запросов.
Конечно, это всегда можно сделать, указывая необходимое планируемое время выполнения запросов, но гораздо проще задать паузу как отрицательное число миллисекунд в поле `max`:
```sql
INSERT INTO task (max, input) SELECT -5000, 'SELECT pg_sleep(10)' FROM generate_series(1, 10); -- выполнить 10 запросов антипараллельно, т.е. последовательно выполняя их с паузой 5 секунд между выполнениями
```
Здесь отрицательное число в поле `max` означает количество миллисекунд паузы между выполнением запросов.
При автоматическом повторении запросов, а также при антипараллельном выполнении запросов с паузами, могут возникнуть интересные ситуации, когда продолжительность запроса больше, чем интервал автоматического повтора или чем пауза между антипараллельными выполнениями.
В таких ситуациях есть два варианта:
1) отсчитывать следующий повтор (или паузу) после окончания выполнения запроса, при этом начало следующей задачи будет всё время сдвигаться, "дрейфовать"
2) либо вычислять повтор (или, соответственно, паузу) от запланированного времени предыдущей задачи, так, что начало следующей задачи будет чётко отстоять от запланированного времени предыдущей задачи на кратный интервал повтора (паузы)

Эти варианты можно задать в булевском поле `drift` (по-умолчанию, там будет `false`).
Существуют ещё несколько полезных полей в таблице с заданиями.
Поле `active` используется для указания интервала (относительно запланированного времени выполнения), когда задача ещё активна, т.е актуальна (по-умолчанию, там будет 1 час).
Если в течении этого времени планировщик не успеет выполнить задачу, то в дальнейшем (когда до неё дойдёт очередь), эта задача не будет выполняться, а будет сразу записана ошибка о том, что задача просрочена.
При этом, очевидно, если задача была повторяющаяся, то будет создано очередное повторение для задачи, которое в дальнейшем уже может успеть выполнится за определённое время.
Если указано булевское поле `delete` (а по-умолчанию оно указано и там `true`) и в результате выполнения запроса нет ошибок и сам результат пустой, то после выполнения планировщик удалит запись о задаче из таблицы с заданиями.
И точно также, если задача была повторяющаяся, то будет создано очередное повторение для задачи.
Также можно ограничить время выполнения задачи, указав неотрицательный интервал в поле `timeout` (по умолчанию там 0, что означает неограниченное время выполнения):
```sql
INSERT INTO task (timeout, input) VALUES ('5 sec', 'SELECT pg_sleep(10)'); -- выполнить запрос с таймаутом 5 секунд
```
В данном случае возникнет ошибка, т.к. время выполнения запроса будет больше таймаута.
Если требуется выполнить много запросов в одной и той же группе, то логичнее будет не запускать для каждого запроса новый фоновый рабочий процесс, а обрабатывать в одном таком процессе множество запросов.
Для управления такими ситуациями используются поле `live`, в котором можно задать интервал жизни фонового рабочего процесса, и/или неотрицательное целочисленное поле `count`, в котором можно ограничить количество запросов, обрабатываемых фоновым рабочим процессом.
Нулевые значение по-умолчанию в обоих этих полях означают то, что фоновый рабочий процесс обработает только один запрос.
Для кастомного форматирования результатов выполнения запросов можно использовать следующие поля.
Если задано булево поле `header` (по-умолчанию true), то в результатах будут показываться заголовки.
Если задано булево поле `string` (по-умолчанию true), то в результатах будут квотироваться только строки.
Поле `delimiter` (по-умолчанию это знак табуляции) задаёт разделитель между колонками в результатах.
Поле `quote` (по-умолчанию это пустая строка) задаёт символ кавычек для квотирования.
Поле `escape` (по-умолчанию это пустая строка) задаёт символ для экранирования.
И, наконец, поле `null` (по-умолчанию это \N) задаёт символ для NULL.
Как уже упоминалось выше, планировщик может быть запущен одновременно в нескольких базах.
Для управления этим используется переменная `pg_task.json`, которая может быть задана только в конфигурационном файле.
Но зато применять её изменения можно даже просто при перечитывании конфигурации.
В этой переменной хранится таблица конфигурации планировщика в сериализованном в json(b) виде, которая состоит из следующих колонок:
- `data` - название базы данных, в которой должен быть запущен планировщик (по-умолчанию это `postgres`)
- `reset` - интервал сброса зависших заданий (по-умолчанию это 1 час)
- `schema` - название схемы, в которой планировщик создаст и будет использовать таблицу с заданиями (по-умолчанию это `public`)
- `table` - название самой таблицы с заданиями (по-умолчанию это `task`)
- `sleep` - интервал между проверками на новые задания (по-умолчанию это 1 секунда)
- `user` - имя пользователя, от которого будет работать планировщик (по-умолчанию это `postgres`)

Т.к. переменная `pg_task.json` хранит json-значение таблицы, то можно опускать некоторые колонки, которые при этом будут заполняться значениями по-умолчанию.
Также, если указанная база и/или пользователь не существуют, то они будут созданы планировщиком.
Например следующая настройка
```conf
pg_task.json = '[{"data":"database1"},{"data":"database2","user":"username2"},{"data":"database3","schema":"schema3"},{"data":"database4","table":"table4"},{"data":"database5","sleep":100}]'
```
запустит планировщик в базе database1 под пользователем database1 (т.к. если не указан пользователь, то его имя берётся как имя базы), в базе database2 под пользователем username2, в базе database3 под пользователем database3 в схеме schema3, в базе database4 под пользователем database4 с таблицей table4, и наконец в базе database5 под пользователем database5 и с интервалом проверки задач в 100 миллисекунд, при этом остальные неуказанные поля будут браться по-умолчанию.

## Будущее или как устроен планировщик.
